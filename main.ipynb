{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:01.547909Z",
     "start_time": "2025-03-20T04:58:01.545409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os"
   ],
   "id": "76e43897c63d63cb",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:01.571067Z",
     "start_time": "2025-03-20T04:58:01.568833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "8a637759580f3f36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:01.593048Z",
     "start_time": "2025-03-20T04:58:01.589593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make sure data directories exist\n",
    "if not os.path.isdir('.\\\\data'):\n",
    "    os.makedirs('.\\\\data')\n",
    "if not os.path.isdir('.\\\\data\\\\train'):\n",
    "    os.makedirs('.\\\\data\\\\train')\n",
    "if not os.path.isdir('.\\\\data\\\\test'):\n",
    "    os.makedirs('.\\\\data\\\\test')"
   ],
   "id": "824caeeccf7b97c1",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:01.606511Z",
     "start_time": "2025-03-20T04:58:01.603416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ModifiedNet(torch.nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super(ModifiedNet, self).__init__()\n",
    "        self.resnet = torch.hub.load(\"pytorch/vision\", \"resnet50\", weights=\"IMAGENET1K_V2\")\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ],
   "id": "6eaa274899e669f8",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:01.617626Z",
     "start_time": "2025-03-20T04:58:01.613701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "categories = []\n",
    "\n",
    "class ModifiedDataSet(Dataset):\n",
    "    def __init__(self, base_directory):\n",
    "        self.img_dir = []\n",
    "        self.NUMBER_OF_OUT_FEATURES = 0\n",
    "\n",
    "        # Loop through each folder in the base directory\n",
    "        for folder_name in os.listdir(base_directory):\n",
    "            folder_path = os.path.join(base_directory, folder_name)\n",
    "\n",
    "            # Check if it's a directory\n",
    "            if os.path.isdir(folder_path):\n",
    "                self.NUMBER_OF_OUT_FEATURES += 1\n",
    "                categories.append(folder_name)\n",
    "                # List all files in the current folder\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                    # Check if it's a file (not a subfolder)\n",
    "                    if os.path.isfile(file_path):\n",
    "\n",
    "                        img = Image.open(file_path).convert(\"RGB\")\n",
    "                        preprocess = transforms.Compose([\n",
    "                            transforms.Resize(256),\n",
    "                            transforms.CenterCrop(224),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ])\n",
    "                        img = preprocess(img)\n",
    "                        self.img_dir.append((img, categories.index(folder_name)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img_dir[idx]\n",
    "\n",
    "    def get_num_labels(self):\n",
    "        return self.NUMBER_OF_OUT_FEATURES\n"
   ],
   "id": "a4d8f6814d245fc6",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Behavior Setting\n",
    "\n",
    "When `use_saved_dataset = True`, the system will try to load previously trained `model.pt`, and `test.pkl` and `train.pkl` which contain the numpy array that store the RGB value of every image in the dataset.\n",
    "\n",
    "If the training or testing data changed, and the model needs to be retrained, set `use_saved_dataset = False`"
   ],
   "id": "7539610ee4f3982d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:02.194523Z",
     "start_time": "2025-03-20T04:58:01.626032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle as pkl\n",
    "\n",
    "use_saved_dataset = True\n",
    "\n",
    "train_dataset: ModifiedDataSet\n",
    "test_dataset: ModifiedDataSet\n",
    "\n",
    "def load_dataset(saved):\n",
    "    global train_dataset, test_dataset\n",
    "    if saved:\n",
    "        if os.path.exists(\"train.pkl\"):\n",
    "            with open(\"train.pkl\", \"rb\") as f:\n",
    "                train_dataset = pkl.load(f)\n",
    "                print(\"Successfully loaded train.pkl\")\n",
    "        else:\n",
    "            train_dataset = ModifiedDataSet(base_directory=\".\\\\data\\\\train\")\n",
    "            with open(\"train.pkl\", \"wb\") as f:\n",
    "                pkl.dump(train_dataset, f)\n",
    "\n",
    "        if os.path.exists(\"test.pkl\"):\n",
    "            with open(\"test.pkl\", \"rb\") as f:\n",
    "                test_dataset = pkl.load(f)\n",
    "                print(\"Successfully loaded test.pkl\")\n",
    "        else:\n",
    "            test_dataset = ModifiedDataSet(base_directory=\".\\\\data\\\\test\")\n",
    "            with open(\"test.pkl\", \"wb\") as f:\n",
    "                pkl.dump(test_dataset, f)\n",
    "    else:\n",
    "        train_dataset = ModifiedDataSet(base_directory=\".\\\\data\\\\train\")\n",
    "        test_dataset = ModifiedDataSet(base_directory=\".\\\\data\\\\test\")\n",
    "        with open(\"train.pkl\", \"wb\") as f:\n",
    "            pkl.dump(train_dataset, f)\n",
    "        with open(\"test.pkl\", \"wb\") as f:\n",
    "            pkl.dump(test_dataset, f)\n",
    "\n",
    "load_dataset(use_saved_dataset)"
   ],
   "id": "5f33d910fbe7bbdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded train.pkl\n",
      "Successfully loaded test.pkl\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:02.203889Z",
     "start_time": "2025-03-20T04:58:02.199463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model: ModifiedNet\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "loss_fn: torch.nn.CrossEntropyLoss\n",
    "optimizer: torch.optim.SGD\n",
    "\n",
    "train_dataloader: DataLoader\n",
    "test_dataloader: DataLoader\n",
    "\n",
    "def load_dataloader():\n",
    "    global train_dataloader\n",
    "    if len(train_dataset) != 0:\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    global test_dataloader\n",
    "    if len(test_dataset) != 0:\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "load_dataloader()"
   ],
   "id": "2d0cbe591bb4576e",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:02.218118Z",
     "start_time": "2025-03-20T04:58:02.215287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "id": "742930724304429",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:02.224500Z",
     "start_time": "2025-03-20T04:58:02.220124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "id": "3d2f89726e5e710d",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:02.351356Z",
     "start_time": "2025-03-20T04:58:02.229079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_test():\n",
    "    if len(train_dataset) == 0:\n",
    "        return\n",
    "    global model\n",
    "    global optimizer\n",
    "    global loss_fn\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    model = ModifiedNet(train_dataset.get_num_labels()).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loop(test_dataloader, model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "    torch.save(model, \"model.pt\")\n",
    "\n",
    "\n",
    "if use_saved_dataset and os.path.exists(\"model.pt\"):\n",
    "    categories = []\n",
    "    base_directory = \".\\\\data\\\\train\"\n",
    "    for folder_name in os.listdir(base_directory):\n",
    "            folder_path = os.path.join(base_directory, folder_name)\n",
    "            # Check if it's a directory\n",
    "            if os.path.isdir(folder_path):\n",
    "                categories.append(folder_name)\n",
    "    model = torch.load(\"model.pt\")\n",
    "    model.to(device)\n",
    "else:\n",
    "    train_and_test()"
   ],
   "id": "b1d0722d22b09e8f",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GUI\n",
    "\n",
    "Helps capturing training/testing data, and showing live prediction. Can run the cell below many times without any error.\n",
    "\n",
    "If new data has been recorded, make sure to set `use_saved_dataset = False`, rerun all previous code cells to reload the data and retrain the network."
   ],
   "id": "59618b4c31308993"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:05:27.760597Z",
     "start_time": "2025-03-20T05:05:25.408005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "should_classify = False\n",
    "\n",
    "def classify_image():\n",
    "    global should_classify\n",
    "    if should_classify:\n",
    "        should_classify = False\n",
    "    else:\n",
    "        if len(train_dataset) != 0 and len(test_dataset) != 0 and len(categories) != 0:\n",
    "            should_classify = True\n",
    "        else:\n",
    "            should_classify = False\n",
    "\n",
    "\n",
    "def update_info():\n",
    "    if not should_classify:\n",
    "        message.set(\"Stopped\")\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Could not open webcam\")\n",
    "        return\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(rgb_frame)\n",
    "        imgtk = ImageTk.PhotoImage(image=pil_image)\n",
    "        image_label.config(image=imgtk)\n",
    "        image_label.image = imgtk\n",
    "        if should_classify:\n",
    "            img = preprocess(pil_image).unsqueeze(0).to(device)\n",
    "            classification = model(img)\n",
    "            result = torch.argmax(classification).item()\n",
    "            message.set(f\"Classifying as {categories[result]}\")\n",
    "\n",
    "\n",
    "    root.after(10, update_info)\n",
    "\n",
    "import time\n",
    "\n",
    "def collect_train():\n",
    "    if input_box.get().strip() == \"\":\n",
    "        messagebox.showerror(\"Error\", \"Label is empty\")\n",
    "        return\n",
    "    global should_classify\n",
    "    should_classify = False\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if not os.path.exists(f\".\\\\data\\\\train\\\\{input_box.get()}\"):\n",
    "            os.makedirs(f\".\\\\data\\\\train\\\\{input_box.get()}\")\n",
    "        cv2.imwrite(f\".\\\\data\\\\train\\\\{input_box.get()}\\\\{time.time() * 1000}.jpg\", frame)\n",
    "\n",
    "def collect_test():\n",
    "    if input_box.get().strip() == \"\":\n",
    "        messagebox.showerror(\"Error\", \"Label is empty\")\n",
    "        return\n",
    "    global should_classify\n",
    "    should_classify = False\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if not os.path.exists(f\".\\\\data\\\\test\\\\{input_box.get()}\"):\n",
    "            os.makedirs(f\".\\\\data\\\\test\\\\{input_box.get()}\")\n",
    "\n",
    "        cv2.imwrite(f\".\\\\data\\\\test\\\\{input_box.get()}\\\\{time.time() * 1000}.jpg\", frame)\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.geometry(\"800x600\")\n",
    "root.title(\"Webcam Capture\")\n",
    "\n",
    "# Create a button that calls the take_picture function when clicked\n",
    "classify_button = tk.Button(root, text=\"Start/stop classify\", command=classify_image, padx=10, pady=5)\n",
    "classify_button.grid(column=0, row=0)\n",
    "\n",
    "\n",
    "message = tk.StringVar()\n",
    "message.set(\"Stopped\")\n",
    "message_label = tk.Label(root, textvariable=message)\n",
    "message_label.grid(column=1, row=0, columnspan=2)\n",
    "\n",
    "collect_data_button = tk.Button(root, text=\"Collect as training\", command=collect_train, padx=10, pady=5)\n",
    "collect_data_button.grid(column=1, row=1)\n",
    "\n",
    "collect_data_button2 = tk.Button(root, text=\"Collect as testing\", command=collect_test, padx=10, pady=5)\n",
    "collect_data_button2.grid(column=2, row=1)\n",
    "\n",
    "input_box = tk.Entry(root, width=30)\n",
    "input_box.insert(0, \"Place your label here\")\n",
    "input_box.grid(column=0, row=1)\n",
    "\n",
    "# Create a label to display the captured image\n",
    "image_label = tk.Label(root)\n",
    "image_label.grid(column=0, row=2, columnspan=3)\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "update_info()\n",
    "root.mainloop()\n",
    "cap.release()\n"
   ],
   "id": "82258d4fbf4cac85",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:07.922848Z",
     "start_time": "2025-03-20T04:58:07.920279Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4a2afd17fac10213",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T04:58:07.931163Z",
     "start_time": "2025-03-20T04:58:07.929557Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fea9a77d1948af1a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
